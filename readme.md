# Next-Word Prediction Using LSTM and GRU

This project implements a **Next-Word Prediction** model using **Long Short-Term Memory (LSTM)** and **Gated Recurrent Unit (GRU)** networks. These Recurrent Neural Networks (RNNs) are designed to handle sequential data effectively and are particularly useful in natural language processing tasks like text generation and prediction.

## Features
- Preprocessing text data for training.
- Implementing and comparing LSTM and GRU architectures.
- Training models on a text dataset.
- Evaluating model performance using metrics like accuracy and perplexity.
- Generating next-word predictions based on user input.

## Requirements
The project is built with Python and requires the following libraries:

Install the required dependencies using the following command:
```bash
pip install -r requirements.txt
```

## Contributing
Contributions are welcome! Feel free to open issues or submit pull requests to enhance the project.

## License
This project is licensed under the MIT License. See the `LICENSE` file for more details.



